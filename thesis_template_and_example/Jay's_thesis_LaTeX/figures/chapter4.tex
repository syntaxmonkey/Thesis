\chapter{Filtering-based Image Upsampling}
\section{Introduction}

\begin{figure}[htbp]
\includegraphics{f1}\centering
\caption{Two input images used in this chapter: treebark, picnic table}
\label{fig:origImages}
\end{figure}

Image upsampling is the operation which estimates a fine-resolution image from a coarse-resolution input 
%\cite{Shan:fiu}.
Figure~\ref{fig:normalInterpolation} shows three basic upsampling interpolation approaches: nearest neighbor interpolation, bilinear interpolation and bicubic interpolation. If you take notice on the boundary and the internal texture of the tree, you will find the interpolation processes have destroyed salient features and introduced clustering, smooth or blurry textures. To make things worse, if we increase the upsampling scale to 10 times or higher, the interpolated pixels' colors will significantly drift away from the original input, which will make the upsampled image blurry, dull and aesthetically unpleasant.

\begin{figure}[htbp] \centering
\includegraphics[width=1.0\textwidth]{f2}
\caption{Three basic interpolation methods. Nearest neighbour interpolation introduces clustering pixel blocks. Bilinear and bicubic interpolation smooth out the sharp edges.}
\label{fig:normalInterpolation}
\end{figure}

The quality of upsampled super-resolution images has risen over the years. Either by using example-based technology or wavelets, the main focus of the field is to produce photorealistic super-resolution images that closely resemble the input and has the same level of details. This is a difficult problem. Therefore, we want to approach this problem differently. We want to simplify the problem by allowing the upsampled images to be abstract or stylized. That is, we detect, sharpen and preserve only the salient features of the input image, such as object boundaries. And we are free to reduce, modify or introduce middle or fine-scale details to the upsampled images, since they no longer need to be photorealistic or faithful to the input image. We hope that we can produce super-resolution images that are sharp, stylized, interesting and aesthetically pleasing.

We attempt to achieve stylized super-resolution images with various filtering techniques. Filtering is a common yet essential part of many signal processing systems, including image processing. Often, we apply various filters to blur or sharpen an image, detect or exaggerate object edges, introduce or remove noise, or achieve non-photorealistic stylization. Image filtering usually involves collecting a pixelâ€™s neighbourhood data, and process the data in some reasonable ways. Due to the difference of purpose, various filters may have very different ways of collecting and processing pixel neighbourhood data. When we put image filtering in the context of image upsampling, the problem becomes more interesting, because we have both original image plane and upsampled image plane to gather our mask data, and we often need much larger masks comparing to common filters.

In this chapter, we propose variations of two filters: cumulative range geodesic filter and bilateral round up filter. Traditionally, cumulative range geodesic filter is used for image abstraction and stylization; bilateral filter is used for edge-preserving image smoothing. Both of the filters respect salient features of the input, which is a great advantage in image upsampling. By adopting these filters, we want to inherit their advantage in edge preserving; by varying these filters, we want to introduce a stylized look to the result super-resolution images. We also explored other post-processing techniques that adds fine details.

Overall, We make two contributions in this chapter:

$\bullet$ We suggest constructing stylized super-resolution images by sacrificing photorealism and the faithfulness to the input. This will simplify the image upsampling problem and produce aesthetically appealing images. There is limited precedent for pursuing stylization in image upsampling or super-resolution.

$\bullet$ We propose a series of operations that achieve sharp super-resolution images. Based on cumulative range geodesic filter and bilateral filter, these operations gather pixel-neighbourhood data in a versatile, edge-sensitive way.  By controlling parameters like the mask size or the number of cross-filtering passes, we are able to achieve different levels of edge sharpness. The filtering process also abstract the upsampled images, which gives the results a painterly looking.


\section{Algorithms}

Figure~\ref{fig:generalPipeline} shows the general pipeline of our approaches. First we upsample the input image. Then we filter or cross-filter the upsampled image using proposed filters. Following this general pipeline, we explored several variations: pre-filtering the input image, cross-filtering the upsampled image with input image, re-filtering the cross-filtered image, adding textures to filtered image, and mask data analysis.

\begin{figure}[htbp]\centering
\includegraphics[width=5.9in]{f3}
\caption{general pipeline of our approaches.}
\label {fig:generalPipeline}
\end{figure}

As for the filtering process, we investigated cumulative range geodesic filtering, which gives strong edge-preserving effect. The disadvantage of this approach is that it overly reduces small scale details. We also introduced one variation of bilateral filter: Bilateral Roundup. It gives a good balance between preserving sharp edges and retaining some small-scale textures. However this filter requires gigantic mask size to produce a good result, and a further improved result requires multiple passes of the filter. 

\subsection{Cumulative range geodesic filter}

Many common filtering techniques find sampling regions centered at each input pixel, and use a function to decide how much each pixel in this region contributes to the output of the mask. Since the mask shape is fixed, often it will include some or many pixels that are not similar to the mask center. Due to the contribution of these pixels, sharp edges from the original images will be smoothed.

Cumulative range geodesic filtering \cite{David:geo} finds arbitrary-shaped masks that can guarantee that all the pixels in this mask are relatively similar to the center. For each input pixel, it keeps a sorted list of neighboring pixels as mask candidates. It uses a weight function to find out which neighboring pixels are similar to the mask center. Every iteration, the top pixel of the list is added to the mask, and the neighbors of that pixel are weighed by weight function and added to the sorted list. Thus, only the pixels that are closest to the center get included in the mask, and only the neighbors of these pixels get to become mask candidates. When the filter reaches the target mask size, it calculates the average color of the mask as the output. Therefore, instead of including all neighboring pixels, the mask center will only consume neighboring pixels that are alike. Thus, instead of being smoothed out, pixels on sharp edges will remain their intensity. Figure ~\ref{fig:geodesicExplanation} shows the mask-shape difference between traditional filtering and cumulative range geodesic filtering.
\begin{figure}[htbp]
\includegraphics[width=1.0\textwidth]{f4}
\caption{Instead of having fixed shaped masks, geodesic filter's mask only includes neighboring pixels that are similar to mask center.}
\label{fig:geodesicExplanation}
\end{figure}

In order to trace the pixels that are similar to mask center, cumulative range geodesic filter uses the following weight function: 
\begin{equation}\label{CRGeoEquation}
W = |I(h)-I(0)| + \gamma \times |I(h)-I(g)|
\end{equation}
where $|I(h)-I(g)|$ represents the incremental color space distance from top pixel $g$ on the sorted candidate list to his neighbor $h$; $|I(h)-I(0)|$ represents the color space distance between mask center $0$ and $h$. Constant $\gamma$  represents the weight distribution of the two terms. This weight function ensures that the mask grows in a path that has the lowest growing cost, and closest color to the mask center. 
The complexity of geodesic filtering is $knlog(n)$ for a k-pixel image with mask size $n$. 

Under the context of large-scale upsampling, plain cumulative range geodesic filtering may not be strong enough for edge preservation. After upsampling, one row of pixels from an input sharp edge will be interpolated to n rows of smoothly transitioned pixels. When these pixels grow masks, they will tend to traverse along the smoothed edge region rather than landing on or off the sharp edge. This behavior will lower the strength of geodesic filtering. 

%insert some result images
%insert some result images
%insert some result images
%insert some result images
%insert some result images
%insert some result images
%insert some result images




\subsection{Bilateral roundup filtering}\label{Bilateral roundup filtering}
Bilateral filtering is widely used for edge-preserving image noise reducing. The idea is weighing each mask pixel by taking both color-space distance and Euclidian distance into account. Our research introduces one variation of bilateral filtering: \textit{bilateral roundup}. Instead of taking all the pixels in a sample region into account, we sort the pixels by their bilateral weight and take only the top n (mask size) pixels as our mask. The process is as follows:

For any pixel $c$ from input image, for mask size $n$, we take a square shaped sampling region $M$ of size $8n$ to $10n$, centered at $c$. For each pixel $p$ in this sampling region $M$, calculate its weight using the bilateral weight function:
\begin{equation}\label {brndupEquation}
W = a \times |I(p)-I(c)|  + b \times |X(p)-X(c)|
\end{equation}
where $|I(p)-I(c)|$ represents the color space distance between pixel $p$ in the sampling region and the center pixel $c$. $|X(p)-X(c)|$ represents their Euclidian distance. At last, we sort the pixels in $M$, and take the top $n$ pixels as the actual mask. Using their average color as output of pixel $c$. Figure \ref{fig:BrndupExplanation} shows one example of bilateral roundup filtering.

\begin{figure}[htbp]\centering
\includegraphics[width=1.0\textwidth]{f5}
\caption{One example of bilateral roundup filter with mask size of 9, sample region size 81. }
\label{fig:BrndupExplanation}
\end{figure}

Bilateral roundup filtering inherits the edge-preserving feature from bilateral filtering. Given a relatively large sampling region, the pixels on a sharp edge will get almost the exact same masks. In fact, on sharp edges and large smooth regions, bilateral roundup filtering is equivalent to cumulative range geodesic filtering. However, for high frequency regions or very fine details, bilateral roundup filtering has strong advantage over cumulative range geodesic filtering. The reason is cumulative range geodesic filtering relies on growing mask, so the mask must be a continuous cloud of pixels. When the mask size exceeds the number of neighboring similar pixels, the mask must cross an edge to keep growing, which will introduce pixels that are not necessarily similar to mask center. However, bilateral roundup filtering samples a large region, and each pixel is weighed individually. Therefore for high frequency regions, bilateral roundup filtering can extract more similar pixels, which grants better small-scale texture preservation. Figure~\ref{fig:comparisonBetweenTwoFilters} shows the difference between two filters on preserving fine details.

\begin{figure}[htbp]\centering
\includegraphics[width=1.0\textwidth]{f6}
\caption{Bilateral roundup filtering preserves high-frequency, fine details better.}
\label{fig:comparisonBetweenTwoFilters}
\end{figure}

The two constants $a$ and $b$ (or $a/b$) in Equation ~\ref{brndupEquation} influences the bilateral roundup filter significantly. When $a/b$ gets closer to zero, this filter will become a smoothing filter. The masks will become circles centered at mask centers. While $b/a$ gets closer to zero, it will still have the edge-preserving feature, but pixels tend to cluster, and the edges tend to get jagged.  Our experiment shows that $a/b$ at $0.1$ to $0.2$ gives acceptable results. The filtering result is also mildly influenced by the mask size and upsampling scale. The complexity of bilateral roundup filtering is $kmlog(m)$ for a $k$-pixel input image with sampling region size of m. 

\subsection{Variations of Bilateral Roundup Filtering}

\subsubsection{Cross-filtering with original image}\label{Cross-filtering with original image}
Under the context of large-scale upsampling, bilateral roundup filtering itself is not quite competent. Similar as cumulative range geodesic filtering, bilateral roundup filtering will generate masks that are saturated by blurry interpolated pixels. Therefore, we explored this approach of calculating masks on the original image rather than the upsampled image. Figure~\ref{fig:BrndupCrossFiltering} shows its improved pipeline.

\begin{figure}[htbp]\centering
\includegraphics[width=1.0\textwidth]{f7}
\caption{Improved pipeline of bilateral round up filtering with original image.}
\label {fig:BrndupCrossFiltering}
\end{figure}

The cross-filtering process is as follows. In order to calculate the mask on original image, for each upsampled pixel, we use the interpolated color as mask center's color. We then divide the interpolated pixel's coordinates by the upsampling scale to find the fractional position on original image. We use this fractional position as the mask center's location. Then we apply bilateral roundup filter on original image and use that output as upsampled pixel's intensity.

This approach has two advantages. First, the mask only sample pixels from original image. The smooth, interpolated neighboring pixels will not saturate the mask, which helps the filter preserve sharp edges. Furthermore, growing masks on the original image requires a significantly smaller mask size, which greatly accelerates the calculation.
\begin{figure}\centering
\includegraphics[width=1.0\textwidth]{f8}
\caption{Bilateral roundup filter on original image.}
\end{figure}

\subsubsection{Multi-passes of bilateral roundup filtering }
To further improve the filtered image from previous approach, we added another step of running several more passes of bilateral roundup filtering. The approach is simple: first using interpolated color and fractional position to filter the upsampled image (as described at Section~\ref{Cross-filtering with original image}). Then we iteratively apply bilateral roundup filtering (as described at Section ~\ref{Bilateral roundup filtering}) on previous passes' results. Figure~\ref{fig:multi-pass pipeline} shows the pipeline of this process.

\begin{figure}[htbp]
\includegraphics[width=1.0\textwidth]{f9}
\caption{pipeline of bilateral roundup filtering multi-passes.  r}
\label{fig:multi-pass pipeline}
\end{figure}

As expected, more passes generates more abstracted images: sharper edges, less small-scale details.  Figure~\ref{fig:multipass} shows results ranging from 0-passes to 3-passes. We think 2nd pass result is the best among them. Its edges are significantly sharper than 1st pass, and the background (forest) isn't as destroyed as the 3rd pass. Also, note that in the 3rd pass result, some edges are a bit jagged from being over-sharpened.  Figure~\ref{fig:2ndPassResult} shows a well-balanced result that preserves strong edges on boundaries of the picnic table, and the medium-scale textures on grass are also preserved.

\begin{figure}[htbp]
\includegraphics[width=1.0\textwidth]{f10}
\caption{More passes of this filter will keep sharpening the edges and eliminating small scale details. }
\label{fig:multipass}
\end{figure}
\begin{figure}[htbp]
\includegraphics[width=1.0\textwidth]{f11}
\caption{A 2nd pass result. Edges are well sharpened while the fine details are not overly removed.}
\label{fig:2ndPassResult}
\end{figure}

\subsubsection{Pre-filtering the original image}


While carrying experiments of applying bilateral roundup filter on original image, constantly we were worried about the quality of the original images. Naturally, upsampling results will suffer from poor original image quality. We cannot expect the upsampled images to be sharp and stylized if the original image is smooth, has jagged edges, or suffers from jpeg artifacts. Thus we added one step of pre-filtering the original image. We apply bilateral roundup filtering on the original image using a relatively small mask size. This process will sharpen the original image a little bit before upsampling. Though not obvious on most images, this extra step improves the masks of poor quality edges or regions. It also helps removing jpeg artifacts. Figure~\ref{fig:prefiltering} shows the pipeline of this process.

\begin{figure}[htbp]
\includegraphics[width=1.0\textwidth]{f12}
\caption{Pre-filtering pipeline.}
\label{fig:prefiltering}
\end{figure}
As shown in figure 13, certain edges (marked by the red box) are slightly better sharpened by pre-filtering the original image.
\begin{figure}[htbp]
\includegraphics[width=1.0\textwidth]{f13}
\caption{Pre-filter original image improves poor quality edge's results}
\end{figure}

\subsubsection{Post-filtering texture enrichment}

The upsampling process, cumulative range geodesic filtering and multiple passes of bilateral roundup filtering all reduce the small-scale details. Even though the results look clean and sharp, we often find the large smooth areas (like the sky) boring, and the areas that are expected to be textured (like the grass, sand) are not textured enough. Thus we decided to add some arbitrary texture to the upsampled image.

\begin{figure}[htbp]
\includegraphics[width=1.0\textwidth]{f14}
\caption{post-filtering texture enrichment pipeline}
\label{fig:textureEnrich}
\end{figure}

Figure~\ref{fig:textureEnrich} shows the pipeline of this post-filtering process. In addition to multiple passes of bilateral round up filtering, we gather several high frequency texture images from online image database, using keywords like grass, gravel, hair, hay, fur, paper, cement. Then based on each upsampled filtered pixel's intensity, we use the scheme shown in figure~\ref{fig:textureDistribution} to distribute the textures. There are two reasons why we distribute the textures in such manner. First, we want different-colored regions adopt different levels of frequency. The varied frequency (or textureness) will help exaggerate salient features, which makes the results look sharper. Second, we want same-colored regions to adopt more or less similar texture. So that within one object, there will exist a consistency of texture. 

\begin{figure}[htbp]
\includegraphics[width=1.0\textwidth]{f15}
\caption{The texture distribution scheme. For instance, for a pixel at intensity 50, it will take the average of a bit over half from texture 1, most of texture 2, and a little bit less than half from texture 3.}
\label{fig:textureDistribution}
\end{figure}

After distributing textures, we cross-filter the texture-enriched image with the original image. This last step is to smooth and even out the textures on large smooth areas of upsampled image. 

\begin{figure}[htbp]
\includegraphics[width=1.0\textwidth]{f16}
\caption{Adding multiple textures to upsampled image.}
\label{fig:textureEnrichBestResult}
\end{figure}


\section{Discussion and Future Work}
Both cumulative range geodesic filtering, bilateral roundup filtering and their variations have edge-preserving features. Cumulative range geodesic filtering gives strong edge-preserving effect. Multiple passes of bilateral roundup filtering has a good balance between preserving large-scale and small-scale features, while it is extremely heavy to compute. 

Our current approaches focus on using different weight functions to gather mask data. But we always process the mask data in a rather primitive way: taking the average intensity of the mask. While there are definitely more sophisticated weight functions that can improve data gathering, mask data analyzing and processing is another direction that may lead to improvement to our results.

Our current experiment results are based on upsampling scales from 2-6. As the scale of upsampling increases, the memory requirement and computational time becomes very demanding. Optimizing the implementation and accelerating the computations will enable us to carry experiments and produce results more efficiently.

Many factors significantly influences the output, such as input image quality and resolution, weight function parameters, upsampling scale, mask size. We need to organize more systematic, controlled experiments to find out the significance of each factor, hence enable better analysis.

It is difficult to quantify and evaluate the results. Certain stylized results may look appealing to some individual while not as much to others. It is relevant to establish a more precise targeting style. In that way the results can be objectively evaluated.
